{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch10 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "\n",
    "from adv_finance import bars, labeling, utils, features, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-talk')\n",
    "plt.style.use('bmh')\n",
    "pd.set_option('display.max_rows', 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet('/nfs/data/interim_2018/TRADE_A233740_DB.parq')\n",
    "data = data.loc[~data.index.duplicated()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>vol</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-02 10:00:03.348</th>\n",
       "      <td>19800</td>\n",
       "      <td>19980</td>\n",
       "      <td>19800</td>\n",
       "      <td>19980</td>\n",
       "      <td>215968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02 10:00:15.776</th>\n",
       "      <td>19980</td>\n",
       "      <td>20015</td>\n",
       "      <td>19980</td>\n",
       "      <td>20005</td>\n",
       "      <td>51025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02 10:00:39.990</th>\n",
       "      <td>20005</td>\n",
       "      <td>20065</td>\n",
       "      <td>20005</td>\n",
       "      <td>20045</td>\n",
       "      <td>49957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02 10:01:11.518</th>\n",
       "      <td>20045</td>\n",
       "      <td>20075</td>\n",
       "      <td>20040</td>\n",
       "      <td>20050</td>\n",
       "      <td>50140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02 10:01:30.166</th>\n",
       "      <td>20050</td>\n",
       "      <td>20080</td>\n",
       "      <td>20045</td>\n",
       "      <td>20080</td>\n",
       "      <td>54775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          open   high    low  close     vol\n",
       "timestamp                                                  \n",
       "2018-01-02 10:00:03.348  19800  19980  19800  19980  215968\n",
       "2018-01-02 10:00:15.776  19980  20015  19980  20005   51025\n",
       "2018-01-02 10:00:39.990  20005  20065  20005  20045   49957\n",
       "2018-01-02 10:01:11.518  20045  20075  20040  20050   50140\n",
       "2018-01-02 10:01:30.166  20050  20080  20045  20080   54775"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primary Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute sides \n",
    "# data['side'] = np.nan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/code/adv_finance/adv_finance/labeling/labeling.py:111: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  target = target.loc[t_events]\n",
      "2019-06-15 17:32:23.052601 100.0 apply_pt_sl_on_t1 done after 0.07 minutes. Remaining 0.0 minutes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.41 s, sys: 52.6 ms, total: 3.46 s\n",
      "Wall time: 7.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# CUSUM Filter \n",
    "daily_vol = stats.get_daily_vol(data['close'], lookback=100)\n",
    "threshold = daily_vol.mean() * 0.2\n",
    "t_events = labeling.cusum_filter(data['close'], threshold)\n",
    "v_barriers = labeling.add_vertical_barrier(t_events=t_events, close=data['close'], num_days=1)\n",
    "\n",
    "\n",
    "# Side Decision by Cusum Filter & Triple Barrier \n",
    "pt_sl = [1, 1]\n",
    "min_ret = 0.01 \n",
    "t_side_events = labeling.get_events(close=data['close'],\n",
    "                                            t_events=t_events,\n",
    "                                            pt_sl=pt_sl,\n",
    "                                            target=daily_vol,\n",
    "                                            min_ret=min_ret,\n",
    "                                            num_threads=8,\n",
    "                                            vertical_barrier_times=v_barriers,\n",
    "                                            side_prediction=None)\n",
    "\n",
    "\n",
    "side_labels = labeling.get_bins(t_side_events, data['close'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metal Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/code/adv_finance/adv_finance/labeling/labeling.py:111: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  target = target.loc[t_events]\n",
      "/nfs/code/adv_finance/adv_finance/labeling/labeling.py:123: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  side_ = side_prediction.loc[target.index]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 147 ms, sys: 35.2 ms, total: 182 ms\n",
      "Wall time: 1.17 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-15 17:32:24.414711 100.0 apply_pt_sl_on_t1 done after 0.02 minutes. Remaining 0.0 minutes.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pt_sl = [1, 2]\n",
    "min_ret = 0.02\n",
    "t_barrier_events = labeling.get_events(close=data['close'],\n",
    "                                            t_events=t_events,\n",
    "                                            pt_sl=pt_sl,\n",
    "                                            target=daily_vol,\n",
    "                                            min_ret=min_ret,\n",
    "                                            num_threads=8,\n",
    "                                            vertical_barrier_times=v_barriers,\n",
    "                                           side_prediction=side_labels['bin'])\n",
    "\n",
    "\n",
    "labels = labeling.get_bins(t_barrier_events, data['close'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 7s, sys: 38.7 ms, total: 1min 7s\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "raw_data = data.copy()\n",
    "\n",
    "# Log Returns\n",
    "raw_data['log_ret'] = np.log(raw_data['close']).diff()\n",
    "\n",
    "# Momentum\n",
    "raw_data['mom1'] = raw_data['close'].pct_change(periods=1)\n",
    "raw_data['mom3'] = raw_data['close'].pct_change(periods=3)\n",
    "raw_data['mom5'] = raw_data['close'].pct_change(periods=5)\n",
    "\n",
    "# Volatility\n",
    "raw_data['volatility_15'] = raw_data['log_ret'].rolling(window=15, min_periods=15, center=False).std()\n",
    "raw_data['volatility_50'] = raw_data['log_ret'].rolling(window=50, min_periods=50, center=False).std()\n",
    "\n",
    "\n",
    "\n",
    "# Serial Correlation (Takes about 4 minutes)\n",
    "window_autocorr = 30\n",
    "raw_data['autocorr_1'] = raw_data['log_ret'].rolling(window=window_autocorr, min_periods=window_autocorr, center=False).apply(lambda x: x.autocorr(lag=1), raw=False)\n",
    "raw_data['autocorr_3'] = raw_data['log_ret'].rolling(window=window_autocorr, min_periods=window_autocorr, center=False).apply(lambda x: x.autocorr(lag=3), raw=False)\n",
    "raw_data['autocorr_5'] = raw_data['log_ret'].rolling(window=window_autocorr, min_periods=window_autocorr, center=False).apply(lambda x: x.autocorr(lag=5), raw=False)\n",
    "\n",
    "# Get the various log -t returns\n",
    "raw_data['log_t1'] = raw_data['log_ret'].shift(1)\n",
    "raw_data['log_t3'] = raw_data['log_ret'].shift(3)\n",
    "raw_data['log_t5'] = raw_data['log_ret'].shift(5)\n",
    "\n",
    "# Remove look ahead bias\n",
    "raw_data = raw_data.shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python372/lib/python3.7/site-packages/pandas/core/indexing.py:1017: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return getattr(section, self.name)[new_key]\n"
     ]
    }
   ],
   "source": [
    "# Get features at event dates \n",
    "X = raw_data \n",
    "\n",
    "# Drop unwanted columns \n",
    "try: \n",
    "    X.drop(['open', 'high', 'low', 'close', 'vol'], axis=1, inplace=True)\n",
    "\n",
    "except Exception as e: \n",
    "    print(e)\n",
    "\n",
    "    \n",
    "y = labels.loc[X.index, 'bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.dropna()\n",
    "X = X.dropna()\n",
    "com_idx = y.index.join(X.index).join(labels.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.loc[com_idx]\n",
    "y = y.loc[com_idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance Classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training, validation and test sets\n",
    "X_training_validation = X['2018-01-01':'2018-10-31']\n",
    "y_training_validation = y['2018-01-01':'2018-10-31']\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_training_validation, y_training_validation, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    1329\n",
       "0.0     684\n",
       "Name: bin, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.concat([y_train, X_train], axis=1, join='inner')\n",
    "train_df['bin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    684\n",
       "0.0    684\n",
       "Name: bin, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upsample the training data to have a 50 - 50 split\n",
    "# https://elitedatascience.com/imbalanced-classes\n",
    "majority = train_df[train_df['bin'] == 0]\n",
    "minority = train_df[train_df['bin'] == 1]\n",
    "\n",
    "new_minority = resample(minority, \n",
    "                   replace=True,     # sample with replacement\n",
    "                   n_samples=majority.shape[0],    # to match majority class\n",
    "                   random_state=42)\n",
    "\n",
    "train_df = pd.concat([majority, new_minority])\n",
    "train_df = shuffle(train_df, random_state=42)\n",
    "\n",
    "train_df['bin'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.3 ms, sys: 4 Âµs, total: 20.3 ms\n",
      "Wall time: 19.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "depth = 2\n",
    "n_estimator = 10\n",
    "\n",
    "\n",
    "# Refit a new model with best params, so we can see feature importance\n",
    "rf2 = RandomForestClassifier(max_depth=depth, n_estimators=n_estimator, criterion='entropy', random_state=42)\n",
    "rf2.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bet Sizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adv_finance.labeling import get_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = rf2.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = pd.Series(y_prob[:, 1], index=X_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>side</th>\n",
       "      <th>t1</th>\n",
       "      <th>trgt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-04 15:12:34.986</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-01-05 15:13:36.604</td>\n",
       "      <td>0.020060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04 15:13:16.432</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-01-05 09:01:17.944</td>\n",
       "      <td>0.020855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04 15:14:53.715</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-01-05 09:01:03.808</td>\n",
       "      <td>0.022589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04 15:15:40.118</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-01-05 09:01:03.808</td>\n",
       "      <td>0.023663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04 15:16:46.975</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-01-05 09:01:17.944</td>\n",
       "      <td>0.025145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         side                      t1      trgt\n",
       "2018-01-04 15:12:34.986   0.0 2018-01-05 15:13:36.604  0.020060\n",
       "2018-01-04 15:13:16.432   1.0 2018-01-05 09:01:17.944  0.020855\n",
       "2018-01-04 15:14:53.715   1.0 2018-01-05 09:01:03.808  0.022589\n",
       "2018-01-04 15:15:40.118   1.0 2018-01-05 09:01:03.808  0.023663\n",
       "2018-01-04 15:16:46.975   1.0 2018-01-05 09:01:17.944  0.025145"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_barrier_events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('t_barrier_events.pickle', 'wb') as f:\n",
    "    pickle.dump(t_barrier_events.to_dict(), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('y_prob.pickle', 'wb') as f:\n",
    "    pickle.dump(y_df.to_dict(), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "bet_size = get_signal(y_df, t_barrier_events0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_betsize = pd.DataFrame(y_df, columns=['Prob'])\n",
    "df_betsize['BetSize'] = bet_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPENDIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
